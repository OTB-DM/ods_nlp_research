{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ce8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir .deeppavlov\n",
    "!wget -P ./.deeppavlov http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt_v1.tar.gz\n",
    "!tar -xzvf ./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1.tar.gz --directory ./.deeppavlov/\n",
    "!rm ./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13368a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersNerPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e03392",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TorchTransformersNerPreprocessor(\n",
    "    vocab_file=\"./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e046361",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"\"\"В сч.расч. по дог. б/н от 22.02.22г. Оплата за ООО \"ТД\"Млечный путь\" по сч.42 Алятина Рустамжона Аглы за ракетное топливо Сумма 120000-00 В т.ч. НДС (20%) 20000-00\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preprocessor([seq])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fae13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ./.deeppavlov http://files.deeppavlov.ai/0.16/ner/ner_rus_bert_torch.tar.gz\n",
    "!tar -xzvf ./.deeppavlov/ner_rus_bert_torch.tar.gz --directory ./.deeppavlov/\n",
    "!rm ./.deeppavlov/ner_rus_bert_torch.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ac3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vocab = SimpleVocabulary(unk_token=[\"O\"], pad_with_zeros=True, save_path='./.deeppavlov/ner_rus_bert_torch/tag.dict',\n",
    "                               load_path='./.deeppavlov/ner_rus_bert_torch/tag.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4a8580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_vocab.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fc391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "config.json  pytorch_model.bin\ttokenizer_config.json  vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e0b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e8d0ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load path '/home/user/PycharmProjects/ods_nlp_research/.deeppavlov/ner_rus_bert_torch/model' differs from save path '/home/user/PycharmProjects/ods_nlp_research/.deeppavlov/ner_rus_bert_torch/model_new' in 'infer' mode for TorchTransformersSequenceTagger.\n",
      "Some weights of the model checkpoint at ./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TorchTransformersSequenceTagger(\n",
    "    n_tags = simple_vocab.len,\n",
    "    pretrained_bert = \"./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1\",\n",
    "    bert_config_file = \"./.deeppavlov/rubert_cased_L-12_H-768_A-12_pt_v1\",\n",
    "    attention_probs_keep_prob = .5,\n",
    "    encoder_layer_ids = [-1],\n",
    "    optimizer_parameters = {\n",
    "          \"lr\": 2e-05,\n",
    "          \"weight_decay\": 1e-06,\n",
    "          \"betas\": [\n",
    "            0.9,\n",
    "            0.999\n",
    "          ],\n",
    "          \"eps\": 1e-06\n",
    "        },\n",
    "    clip_norm = 1.0,\n",
    "    min_learning_rate = 1e-07,\n",
    "    learning_rate_drop_patience = 30,\n",
    "    learning_rate_drop_div = 1.5,\n",
    "    load_before_drop = True,\n",
    "    save_path = \"./.deeppavlov/ner_rus_bert_torch/model_new\",\n",
    "    load_path = \"./.deeppavlov/ner_rus_bert_torch/model\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = model(result[2],result[4],result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97101fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3,\n",
       "        3, 3, 3, 3, 3, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10cf9753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_vocab.idxs2toks(output_model[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7e078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
